{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10 # the higher the better\n",
    "IMG_WIDTH = 128 # for faster computing on kaggle\n",
    "IMG_HEIGHT = 128 # for faster computing on kaggle\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = './V3/Train/Train_labels'\n",
    "TEST_PATH = './V3/Test/Test_labels'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "for root, dirs, files in os.walk(TRAIN_PATH, topdown=False):\n",
    "    for name in files:\n",
    "        if(name.lower().endswith('.bmp')):\n",
    "            # [23:] removes the prefix\n",
    "            train_ids.append(os.path.join(root, name)[23:])\n",
    "test_ids = []\n",
    "for root, dirs, files in os.walk(TEST_PATH, topdown=False):\n",
    "    for name in files:\n",
    "        if(name.lower().endswith('.bmp')):\n",
    "            # [21:] removes the prefix\n",
    "            test_ids.append(os.path.join(root, name)[21:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c0ccea2ffa4957bbeaedd9c2e55b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=182.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd9ff51ced0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    # resize training image and add into list as np array\n",
    "    img = imread('./V3/Train/Train_RGB/'+id_)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    # make all bg pixels in mask image red\n",
    "    img = imread(TRAIN_PATH+id_)\n",
    "    size = img.shape\n",
    "    redColor = [255, 0, 0]\n",
    "    for x in range(size[0]):\n",
    "        for y in range(size[1]):\n",
    "            pixel = img[x, y]\n",
    "            if(pixel[0] == redColor[0] and pixel[1] == redColor[1] and pixel[2] == redColor[2]):\n",
    "                img[x, y] = 0\n",
    "    # make mask image boolean matrix (0 for bg and 1 for mask)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    img = np.clip(img, 0, 1)\n",
    "    for x in range(IMG_WIDTH):\n",
    "        for y in range(IMG_HEIGHT):\n",
    "            pixel = img[x, y]\n",
    "            if (any(z > 0 for z in pixel)):\n",
    "                Y_train[n][x][y] = 1\n",
    "            else:\n",
    "                Y_train[n][x][y] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cdd58bb82e453697281b2c539e239d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=96.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    img = imread('./V3/Test/Test_RGB/'+id_)[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# Creating the training Image and Mask generator\n",
    "image_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')\n",
    "mask_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')\n",
    "\n",
    "# Keep the same seed for image and mask generators so they fit together\n",
    "\n",
    "image_datagen.fit(X_train[:int(X_train.shape[0]*0.9)], augment=True, seed=seed)\n",
    "mask_datagen.fit(Y_train[:int(Y_train.shape[0]*0.9)], augment=True, seed=seed)\n",
    "\n",
    "x=image_datagen.flow(X_train[:int(X_train.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
    "y=mask_datagen.flow(Y_train[:int(Y_train.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "# Creating the validation Image and Mask generator\n",
    "image_datagen_val = image.ImageDataGenerator()\n",
    "mask_datagen_val = image.ImageDataGenerator()\n",
    "\n",
    "image_datagen_val.fit(X_train[int(X_train.shape[0]*0.9):], augment=True, seed=seed)\n",
    "mask_datagen_val.fit(Y_train[int(Y_train.shape[0]*0.9):], augment=True, seed=seed)\n",
    "\n",
    "x_val=image_datagen_val.flow(X_train[int(X_train.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
    "y_val=mask_datagen_val.flow(Y_train[int(Y_train.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(x, y)\n",
    "val_generator = zip(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred = tf.dtypes.cast(y_pred > t, tf.int32)\n",
    "#         y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 128, 128, 3)  0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 128, 128, 16) 448         lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 128, 128, 16) 0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 128, 128, 16) 2320        dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 64, 64, 16)   0           conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 64, 64, 32)   4640        max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 64, 64, 32)   0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 64, 64, 32)   9248        dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 32, 32, 32)   0           conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 32, 32, 64)   18496       max_pooling2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 32, 32, 64)   0           conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 32, 32, 64)   36928       dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 16, 16, 64)   0           conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 16, 16, 128)  73856       max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 16, 16, 128)  0           conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 16, 16, 128)  147584      dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling2D) (None, 8, 8, 128)    0           conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 8, 8, 256)    295168      max_pooling2d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 8, 8, 256)    0           conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 8, 8, 256)    590080      dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_29 (Conv2DTran (None, 16, 16, 128)  131200      conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 16, 16, 256)  0           conv2d_transpose_29[0][0]        \n",
      "                                                                 conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 16, 16, 128)  295040      concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 16, 16, 128)  0           conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 16, 16, 128)  147584      dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_30 (Conv2DTran (None, 32, 32, 64)   32832       conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 32, 32, 128)  0           conv2d_transpose_30[0][0]        \n",
      "                                                                 conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 32, 32, 64)   73792       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 32, 32, 64)   0           conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 32, 32, 64)   36928       dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_31 (Conv2DTran (None, 64, 64, 32)   8224        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 64, 64, 64)   0           conv2d_transpose_31[0][0]        \n",
      "                                                                 conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 64, 64, 32)   18464       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 64, 64, 32)   0           conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 64, 64, 32)   9248        dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_32 (Conv2DTran (None, 128, 128, 16) 2064        conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 128, 128, 32) 0           conv2d_transpose_32[0][0]        \n",
      "                                                                 conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 128, 128, 16) 4624        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 128, 128, 16) 0           conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 128, 128, 16) 2320        dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 128, 128, 1)  17          conv2d_151[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 202s 806ms/step - loss: 2028.8688 - mean_io_u: 0.2277 - val_loss: 0.6254 - val_mean_io_u: 0.2592\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62540, saving model to model-dsbowl2018-1.h5\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 199s 798ms/step - loss: 187501910.4708 - mean_io_u: 0.2848 - val_loss: 34510.6328 - val_mean_io_u: 0.3273\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.62540\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 198s 791ms/step - loss: 2396024002.5622 - mean_io_u: 0.3300 - val_loss: 47619312.0000 - val_mean_io_u: 0.3429\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.62540\n"
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(patience=3, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit_generator(train_generator, validation_data=val_generator, validation_steps=10, steps_per_epoch=250,\n",
    "                              epochs=3, callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-28f4858f86cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model-dsbowl2018-1.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpreds_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_model('model-dsbowl2018-1.h5', compile=False)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "# preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "# preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "# preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "# preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))\n",
    "imshow(preds_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
